---
title: 多线程、多进程
titleTemplate: Python笔记
---

单线程执行效率低--一个窗口
<br>多线程执行效率高--多个窗口

进程：运行中的程序，操作系统为进程分配内存等，如：Anaconda。【公司】
<br>线程：程序内，可以直接被CPU调度的执行过程，包含在进程中，是进程中的实际运作单位。【员工】

## 1. 什么时候用多线程？什么时候用多进程？
<br>&emsp;&emsp;多线程：任务相对统一，互相特别相似
<br>&emsp;&emsp;多进程：多个任务相对独立，很少有交集

```python
def f1(name):
    for i in range(5):
        print(name,i)
```

```python
#单线程        
if __name__=='__main__':
    #一个执行完了再执行下一个
    f1('numpy')
    f1('pandas')
    f1('matplotlib')
    f1('pyecharts')
```

    numpy 0
    numpy 1
    numpy 2
    numpy 3
    numpy 4
    pandas 0
    pandas 1
    pandas 2
    pandas 3
    pandas 4
    matplotlib 0
    matplotlib 1
    matplotlib 2
    matplotlib 3
    matplotlib 4
    pyecharts 0
    pyecharts 1
    pyecharts 2
    pyecharts 3
    pyecharts 4
    

<b>import threading</b>，后面<b>threading.Thread(target=f,args=())</b>
<br>或<b>from threading import Thread</b>，后面<b>Thread(target=f,args=())</b>

## 2. 多线程
### 2.1 写法一
<b>t1=threading.Thread(target=f,args=(参数,))</b>
<br>&emsp;&emsp;创建一个线程，可创建多个；
<br>&emsp;&emsp;target是目标函数名，args是函数f的传入参数，函数没参数的话可以不写args；
<br>&emsp;&emsp;args可以是列表/元组，加逗号将参数序列解包，把逗号分隔的参数分别传给f；
<br>&emsp;&emsp;不用逗号的话会把整个列表/元组作为一个单独参数穿个f；
<br><b>t1.start()</b>，启动线程

### 2.2 写法二
（1）创建类；（2）继承threading.Thread；
<br>（3）初始化传入参数，本身和父类都要初始化；
<br>（4）重写run方法，里面是要执行的目标函数语句

### 2.3 线程锁
线程锁——确保在任何时间点只有一个线程可以访问被锁定的资源，避免多个线程同时对共享资源进行修改引起的数据竞争和不一致性
<br><b>lock=threading.Lock()</b>，创建锁对象
<br><b>lock.acquire()</b>，申请获得锁
<br><b>lock.release()</b>，释放锁

```python
#多线程
#写法1
import threading
import time

#不用time的话太快，还是显示原顺序
def f2(name):
    #创建一个锁对象
    lock=threading.Lock()
    
    for i in range(5):
        lock.acquire()#申请获得锁
        # time.sleep(0.1)
        print(name,i)
        # time.sleep(0.1)
        lock.release()#释放锁
        time.sleep(0.1)
    
if __name__=='__main__':
        
    #创建线程，后面参数target是要执行的目标函数

    #下面这四个不行，在创建线程的同时就调用了函数，而不是将f作为目标函数
    # t1=threading.Thread(target=f('numpy'))
    # t2=threading.Thread(target=f('pandas'))
    # t3=threading.Thread(target=f('matplotlib'))
    # t4=threading.Thread(target=f('pyecharts'))

    #参数args列表和元组都行
    t1=threading.Thread(target=f2,args=('numpy',))
    t2=threading.Thread(target=f2,args=('pandas',))
    t3=threading.Thread(target=f2,args=('matplotlib',))
    t4=threading.Thread(target=f2,args=('pyecharts',))

    #启动线程
    t1.start()
    t2.start()
    t3.start()
    t4.start()
```

    numpy 0
    pandas 0
    matplotlib 0
    pyecharts 0
    matplotlib 1
    pandas 1
    numpy 1
    pyecharts 1
    pandas 2
    numpy 2
    pyecharts 2
    matplotlib 2
    pandas 3
    pyecharts 3
    numpy 3
    matplotlib 3
    matplotlib 4
    numpy 4
    pandas 4
    pyecharts 4
    

```python
#写法2
import threading
lock=threading.Lock()
class MyThread(threading.Thread):
    def __init__(self,name):
        #继承之后要获得父类的初始化
        #调用父类的构造函数初始化线程对象，三种都行

        #多继承/单继承，指明用哪个父类进行初始化
        super(MyThread,self).__init__()
        #单继承，只有一个父类，省略
        # super().__init__()
        #指明哪个父类初始化
        # threading.Thread.__init__(self)
        self.name=name

    def run(self):
        for i in range(5):
            #运行太快就显示乱了
            lock.acquire()
            time.sleep(0.1)
            print(self.name,i)
            time.sleep(0.1)
            lock.release()
            time.sleep(0.1)

#创建类对象
c1=MyThread('numpy')
c2=MyThread('pandas')
c3=MyThread('matplotlib')
c4=MyThread('pyecharts')

#启动线程
c1.start()
c2.start()
c3.start()
c4.start()
```

    numpy 0
    pandas 0
    matplotlib 0
    pyecharts 0
    numpy 1
    pandas 1
    matplotlib 1
    pyecharts 1
    numpy 2
    pandas 2
    matplotlib 2
    pyecharts 2
    numpy 3
    pandas 3
    matplotlib 3
    pyecharts 3
    numpy 4
    pandas 4
    matplotlib 4
    pyecharts 4
    

### 2.4 线程池
<b>from concurrent.futures import ThreadPoolExecutor</b>
<br>线程太多时用。比如池中可以同时执行10个线程，某个执行完了再让下一个线程进来执行.

```python
#线程池
from concurrent.futures import ThreadPoolExecutor

if __name__=='__main__':
    #线程池最多同时运行2个进程
    with ThreadPoolExecutor(2) as t:
        #往线程池中提交任务
        t.submit(f2,'遥感')
        t.submit(f2,'测绘')
        t.submit(f2,'机器学习')
        t.submit(f2,'人工智能')
#提交了四个，同时运行的只有两个
```

    遥感 0
    测绘 0
    遥感 1
    测绘 1
    测绘 2
    遥感 2
    测绘 3
    遥感 3
    测绘 4
    遥感 4
    机器学习 0
    人工智能 0
    机器学习 1
    人工智能 1
    人工智能 2
    机器学习 2
    人工智能 3
    机器学习 3
    机器学习 4
    人工智能 4
    

```python
#线程池
from concurrent.futures import ThreadPoolExecutor

#有返回值
def f3(name):
    print(name,end='')
    return ' '+name+'处理完成'
def fn(res):
    print(res.result()+' 哦')
    
l=['遥感','测绘','机器学习','人工智能','遥感物理','遥感原理与方法','测量平差','微波遥感',\
   '定量遥感','极地遥感','数字地形测量','海洋遥感','卫星','FY-4A','Landsat','辐射反演']
if __name__=='__main__':
    with ThreadPoolExecutor(3) as t:
        #.add_done_callback(fn)任务完成之后拿到返回值要做什么，立即执行，参数是函数名
        for i in l:
            t.submit(f3,i).add_done_callback(fn)
            time.sleep(0.4)
#提交了16个，每次运行3个
#可以看到最后一个单着
```

    遥感 遥感处理完成 哦
    测绘 测绘处理完成 哦
    机器学习 机器学习处理完成 哦
    人工智能 人工智能处理完成 哦
    遥感物理 遥感物理处理完成 哦
    遥感原理与方法 遥感原理与方法处理完成 哦
    测量平差 测量平差处理完成 哦
    微波遥感 微波遥感处理完成 哦
    定量遥感 定量遥感处理完成 哦
    极地遥感 极地遥感处理完成 哦
    数字地形测量 数字地形测量处理完成 哦
    海洋遥感 海洋遥感处理完成 哦
    卫星 卫星处理完成 哦
    FY-4A FY-4A处理完成 哦
    Landsat Landsat处理完成 哦
    辐射反演 辐射反演处理完成 哦
    

## 2.5. 映射
<b>t.map(f3,l)</b>，按顺序对l中每个元素作为f3的参数执行f3，返回<b>生成器</b>

```python
#线程池
from concurrent.futures import ThreadPoolExecutor

#有返回值
def f3(name):
    print(name+'处理完了')
    return name+'处理完成'
l=['遥感','测绘','机器学习','人工智能','遥感物理','遥感原理与方法','测量平差','微波遥感',\
   '定量遥感','极地遥感','数字地形测量','海洋遥感','卫星','FY-4A','Landsat','辐射反演']

if __name__=='__main__':
    with ThreadPoolExecutor(3) as t:
        #映射，按顺序对l中每个元素作为f3的参数
        t.map(f3,l)

#提交了16个，每次运行3个
#可以看到最后一个单着
```

    遥感处理完了
    测绘处理完了
    机器学习处理完了
    人工智能处理完了
    遥感物理处理完了
    遥感原理与方法处理完了
    测量平差处理完了
    微波遥感处理完了
    定量遥感处理完了
    极地遥感处理完了
    数字地形测量处理完了
    海洋遥感处理完了
    卫星处理完了
    FY-4A处理完了
    Landsat处理完了
    辐射反演处理完了
    

### 2.6 线程池例子

```python
#北京新发地菜市场菜价
import requests
from concurrent.futures import ThreadPoolExecutor

#爬取一页的数据
def get_html(data):
    url='http://www.xinfadi.com.cn/getPriceData.html' 
    try:
        r=requests.post(url,data=data)
        r.encoding=r.apparent_encoding
    except:
        print('爬取失败！')
    return r.json()

#读取信息
def get_info(Json):
    global page_
    page_+=[Json.result()['current'] for k in range(20)]#当前页码复制20份
    
    info=Json.result()['list']
    for i in info:
        global Id
        global Name
        global Cat
        global lp
        global hp
        global ap
        global place
        global unitInfo
        global date
        Id.append(i['id'])
        Name.append(i['prodName'])
        Cat.append(i['prodCat'])
        lp.append(i['lowPrice'])
        hp.append(i['highPrice'])
        ap.append(i['avgPrice'])
        place.append(i['place'])
        unitInfo.append(i['unitInfo'])
        date.append(i['pubDate'])

#保存数据
def save_info(page_,Id,Name,Cat,lp,hp,ap,place,unitInfo,date):
    import pandas as pd
    data=[j for j in zip(page_,Id,Name,Cat,lp,hp,ap,place,unitInfo,date)]
    column=['页码','id','菜名','分类','最低价','最高价','平均价','产地','单位','日期']
    df=pd.DataFrame(data,index=range(1,len(data)+1),columns=column)
    df.to_excel('../data/ThreadPool/北京新发地菜市场.xlsx')
    #文件打开状态时保存失败会报错
    print('保存成功')

def pages(page):
    with ThreadPoolExecutor(100) as t:
        for i in range(1,page+1):
            data={'current':i}
            t.submit(get_html,data).add_done_callback(get_info)

if __name__=='__main__':
    import time
    t1=time.time()
    page_,Id,Name,Cat,lp,hp,ap,place,unitInfo,date=[],[],[],[],[],[],[],[],[],[]
    s=input('想爬取多少页数据？')
    pages(eval(s))
    save_info(page_,Id,Name,Cat,lp,hp,ap,place,unitInfo,date)
    t2=time.time()
    print(f'多线程总耗时：{round(t2-t1,2)}秒')
```

    想爬取多少页数据？ 100
    保存成功
    多线程总耗时：20.12秒
    

```python
#大致的时间，同一线程数每次的时间也会不同
# 爬取100页
# 最大线程数为1（单线程）——95.52秒
# 最大线程数为5——27.16秒
# 最大线程数为10——23.85秒
# 最大线程数为25——25.37秒
# 最大线程数为50——22.22秒
# 最大线程数为100——20.12秒
```

```python

```

```python

```

```python

```

## 3. 多进程

不用等链接全爬取完再下载，而是边爬取链接边访问链接，访问比爬取快则阻塞等着

### 3.1 用法
<b>from multiprocessing import Process</b>，后面<b>Process(target=f,args=())</b>
<br>或<b>import multiprocessing</b>，后面再<b>multiprocessing.Process(target=f,args=())</b>
<br>这里的操作和多线程一样

进程池和线程池操作也一模一样，不过几乎不用
<br><b>from concurrent.futures import ProcessPoolExecutor</b>

两个进程之间独立，进行数据传输需要借助一个中间件——队列
<br><b>from multiprocessing import Queue</b>
<br>&emsp;&emsp;创建队列，<b>q=Queue()</b>
<br>&emsp;&emsp;在进程中把队列作为args的参数传进去，在进程的函数中修改队列
<br>&emsp;&emsp;往队列中添加东西，<b>q.put(x)</b>，可以多次添加
<br>&emsp;&emsp;读取队列中的东西，<b>q.get()</b>，先加先读，可以依次读取
<br>&emsp;&emsp;获取队列大小，<b>q.qsize()</b>
<br>&emsp;&emsp;判断队列是否为空，作为结束标志，<b>q.empty()</b>

两个进程之间数据传输也可以在每个进程的函数中修改全局变量，再读取全局变量来实现

```python
import multiprocessing
import time

def func(name):
    for i in range(9800,9812):
        time.sleep(0.2)
        print(name,chr(i))
        time.sleep(0.2)

if __name__=='__main__':
    p1=multiprocessing.Process(target=func,args=('一',))
    p2=multiprocessing.Process(target=func,args=('二',))
    p3=multiprocessing.Process(target=func,args=('三',))

    p1.start()
    p2.start()
    p3.start()
    # 等p1结束了再执行之后的代码
    p1.join() 
#anaconda中没输出
#保存为py文件在Anaconda Prompt中试了，没问题
```

### 3.2 多进程例子
<br>三个进程：爬取链接、下载图片、计时

```python
from multiprocessing import Process,Queue

#根据输入关键词返回页面链接
def get_img_url(s,q):
    import requests
    url='https://www.logosc.cn/api/so/get?'
    #存在三个链接的列表
    img_url=[]
    #先爬取前2页的图片
    for i in range(1,6):
        sign1,sign2,sign3=1,1,1
        param1={
            'category': 'unsplash',
            'isNeedTranslate': 'true',
            'keywords': s,
            'page': i,
            'pageSize': 20
        }
        param2={
        'category': 'pexels',
        'isNeedTranslate': 'true',
        'keywords': s,
        'page': i,
        'pageSize': 20
        }
        param3={
        'category': 'pixabay',
        'isNeedTranslate': 'false',
        'keywords': s,
        'page': i,
        'pageSize': 20
        }
        try:
            r1=requests.get(url,params=param1)
        except:
            sign1=0
            print('爬取失败！')
        try:
            r2=requests.get(url,params=param2)
            print('爬取失败！')
        except:
            sign2=0
        try:
            r3=requests.get(url,params=param3)
            print('爬取失败！')
        except:
            sign3=0
        if sign1==1:
            for j in r1.json()['data']:
                tmp=j['large_img_path']['url']
                #第一个\用来转义，目标是替换\为空
                tmp=tmp.replace('\\','')
                q.put(tmp)
        if sign2==1:
            for j in r2.json()['data']:
                tmp=j['large_img_path']['url']
                tmp=tmp.replace('\\','')
                q.put(tmp)
        if sign3==1:
            for j in r3.json()['data']:
                tmp=j['large_img_path']['url']
                tmp=tmp.replace('\\','')
                q.put(tmp)

                
#接收链接列表，分别下载
def download_pool(s,q):
    import os
    from concurrent.futures import ThreadPoolExecutor

    #建立搜索结果的文件夹
    os.chdir('D:/桌面/python/爬虫/data')
    p=f'multiprocessing/{s}'
    if not os.path.exists(p):
        os.makedirs(p)
    count=1
    with ThreadPoolExecutor(100)as t:
        while 1:
            url=q.get()
            li=[url,s,count]
            t.submit(download,li)
            count+=1

        
def download(li): 
    import requests
    url=li[0]
    s=li[1]
    count=li[2]
    sign=1
    try:
        r=requests.get(url)
        # r.encoding=r.apparent_encoding
    except:
        sign=0
        print('爬取失败！')
    if sign==1:
        with open(f'D:/桌面/python/爬虫/data/multiprocessing/{s}/{s}-{count}.jpg','wb')as f:
            f.write(r.content)

def ct(t1):
    import time
    while True:  
        t2=time.time()
        print(f'\r正在运行中...已用时{round(t2-t1,2)}秒',end='')
    

if __name__=='__main__':
    import time
    s=input('想下载什么图片？')
    q=Queue()
    t1=time.time()
    #用队列联系两个进程，或者直接在获取链接函数中把链接加到全局变量中
    #p3用于全局计时
    p1=Process(target=get_img_url,args=(s,q,))
    p2=Process(target=download_pool,args=(s,q,))
    p3=Process(target=ct,args=(t1,))
    p3.start()
    p1.start()
    p2.start()
#多进程在jupyterlab上运行不了，在vscode中没问题
#理论上是这样，但好像很多图片下载失败
#开100个线程，刚开始很快，后面越来越慢...
#本身图片也比较大...
#原理理解了
```

    想下载什么图片？ 卫星
    

